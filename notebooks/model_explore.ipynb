{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd062cfbefde3460959c4eddda3e28ff7e666a58a9f2ea7341e4434581c548a266d",
   "display_name": "Python 3.9.2 64-bit ('deeprad_v1': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\nYou are using device: cpu\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import gc\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# raytune\n",
    "# from ray import tune\n",
    "# from ray.tune import CLIReporter\n",
    "# from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "# sci py stuff\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set path\n",
    "deeprad_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "if deeprad_dir not in sys.path:\n",
    "  sys.path.insert(0, deeprad_dir)\n",
    "\n",
    "\n",
    "# Import deeprad models\n",
    "from deeprad.model import Autoencoder, CustomDataSet\n",
    "from deeprad import utils\n",
    "import deeprad.traintest_utils as traintest_utils\n",
    "fd, pp = utils.fd, utils.pp\n",
    "\n",
    "# Set seeds/device\n",
    "np.random.seed(2)  # TODO: confirm right location?\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else 'cpu'\n",
    "print(\"You are using device: %s\" % device)\n",
    "\n",
    "# Data folders\n",
    "TARGET_FOLDER_PATH = os.path.join(deeprad_dir, \"data/traintest/out_data\")\n",
    "CHANNEL_FOLDER_PATH = os.path.join(deeprad_dir, \"data/traintest/in_data\")\n",
    "assert os.path.isdir(TARGET_FOLDER_PATH) and os.path.isdir(CHANNEL_FOLDER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train size: 1972, test size: 493\ntrain_size / batch_size = 1972 / 5 = 394.4\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "run_train = False\n",
    "max_epochs = 2\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-5\n",
    "batch_size = 5\n",
    "# TODO: SGD/Adam/error\n",
    "\n",
    "# Model\n",
    "model_fpath = 'model_{}'.format('epoch_{}_lr_{}'.format(max_epochs, learning_rate))\n",
    "model_fpath = model_fpath.replace('.', '_')\n",
    "model_fpath = os.path.join(deeprad_dir, 'models', model_fpath + '.pt')\n",
    "\n",
    "RUN_TRAIN = True\n",
    "\n",
    "# Load training/test set\n",
    "dataset = CustomDataSet(TARGET_FOLDER_PATH, CHANNEL_FOLDER_PATH,\n",
    "                        transform=transforms.ToTensor(), device=device)\n",
    "train_size = int(len(dataset) * .8)\n",
    "test_size = len(dataset) - train_size\n",
    "train_data, test_data = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "iters = train_size // batch_size\n",
    "\n",
    "print('train size: {}, test size: {}'.format(train_size, test_size))\n",
    "\n",
    "print('train_size / batch_size = {} / {} = {}'.format(train_size, batch_size, train_size / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------\n",
    "# training\n",
    "#---------------------------\n",
    "if run_train:\n",
    "  model = Autoencoder(device)\n",
    "  model = model.to(device)\n",
    "\n",
    "  start_time = time.time()\n",
    "  print(\"Training {} data, over {} epochs\".format(train_size, max_epochs))\n",
    "\n",
    "  torch.manual_seed(42)\n",
    "  criterion = nn.MSELoss() # mean square error loss\n",
    "  optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "  train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "  outputs_train = [0] * max_epochs\n",
    "  train_loss_arr = []\n",
    "\n",
    "  for epoch in range(max_epochs):\n",
    "      start = time.time()\n",
    "      for i, (inputs, labels) in enumerate(train_loader):\n",
    "          input_batch, label_batch = inputs.to(device), labels.to(device)\n",
    "\n",
    "          # forward pass\n",
    "          recon_batch = model.forward(input_batch)\n",
    "          # calc loss\n",
    "          loss = criterion(recon_batch, label_batch)\n",
    "\n",
    "          # calc gradient with autograd\n",
    "          optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          if i == (iters - 1):\n",
    "            print('Epoch:{}, Loss:{:.4f}'.format(epoch + 1, loss))\n",
    "            outputs_train[epoch] = (label_batch, recon_batch)\n",
    "\n",
    "          # For learning curves\n",
    "          train_loss_arr.append(loss) \n",
    "\n",
    "          del inputs; del label_batch; del recon_batch; del loss; del i\n",
    "      \n",
    "  print('time took training {}.'.format(utils.timer(start_time, time.time())))\n",
    "\n",
    "  # Save Model\n",
    "  torch.save(model, model_fpath)\n",
    "  print('Viewing Train Images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# testing\n",
    "#---------------------------\n",
    "\n",
    "# testing loop\n",
    "with torch.no_grad():  # to prevent out of memory errors\n",
    "    model = torch.load(model_fpath, map_location=torch.device('cpu'))\n",
    "    model.eval()\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "\n",
    "    outputs_test = [0] * test_size\n",
    "    test_loss_arr = []\n",
    "    for input_batch, label_batch in test_loader:\n",
    "        input_batch = inputs.to(device)\n",
    "        recon_batch = model(inputs)\n",
    "        \n",
    "        loss = criterion(recon_batch, label_batch)\n",
    "        test_loss_arr.append(loss)\n",
    "        outputs_test[i] = (inputs, recon)\n",
    "\n",
    "    # Viz loss \n",
    "    _outputs_test = outputs_test[::20]  # 20\n",
    "    print(len(_outputs_test))\n",
    "\n",
    "    loss_img_fpath = 'test_loss_' + model_fpath.replace('.pt', '.jpg')\n",
    "    print('Save img at: {}'.format(loss_img_fpath))\n",
    "    viz_loss(_outputs_test, img_fpath=loss_img_fpath, img_title='Test Loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "25\nSave img at: test_loss_/mnt/c/Users/saeran2/master/git/deeprad/models/model_epoch_2_lr_0_001.jpg\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'clean_img4rad' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-ac3ce62e8b11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss_img_fpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test_loss_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_fpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Save img at: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_img_fpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mviz_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_outputs_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_fpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_img_fpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_title\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Test Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-4a5822076bfe>\u001b[0m in \u001b[0;36mviz_loss\u001b[0;34m(outputs, img_fpath, img_title, xdim)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mrecon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecon_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_img4rad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mrecon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_img4rad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_img4rad' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss curves \n",
    "\n",
    "f, a = plt.plot()\n",
    "#train_loss_arr\n"
   ]
  }
 ]
}